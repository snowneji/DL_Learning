{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN Implementation\n",
    "\n",
    "- with tanh activation\n",
    "\n",
    "- with gradient clipping\n",
    "\n",
    "### Author: Yifan Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Helper Functions:\n",
    "def d_tanh(x):\n",
    "\n",
    "    return 1 - np.tanh(x)*np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    '''Softmax'''\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally at each time step of forward, we do:\n",
    "\n",
    "    a_now = activation_relu(Waa * a_previous + Wax * X_now  + ba)\n",
    "    y_hat = Softmax(activation_relu(Wya*a_now + by))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    'hello',\n",
    "    'jello',\n",
    "    'kello',\n",
    "    'yello',\n",
    "    'noon',\n",
    "    'moon',\n",
    "    'soon',\n",
    "    'zoon'\n",
    "]\n",
    "data = [list(word) for word in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 6,\n",
       " 'h': 3,\n",
       " 'j': 10,\n",
       " 'k': 9,\n",
       " 'l': 7,\n",
       " 'm': 8,\n",
       " 'n': 2,\n",
       " 'o': 11,\n",
       " 's': 1,\n",
       " 'y': 5,\n",
       " 'z': 4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict:\n",
    "c2id = {v:k+1 for k,v in enumerate(set([j for i in data for j in i]))}\n",
    "c2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2id[''] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding:\n",
    "def dat_encode(data,c2id):\n",
    "    new_data =[]\n",
    "    for word in data:\n",
    "        new_word = []\n",
    "        for char in word:\n",
    "            new_word.append(c2id[char])\n",
    "        new_data.append(new_word)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 7, 7, 11],\n",
       " [10, 6, 7, 7, 11],\n",
       " [9, 6, 7, 7, 11],\n",
       " [5, 6, 7, 7, 11],\n",
       " [2, 11, 11, 2],\n",
       " [8, 11, 11, 2],\n",
       " [1, 11, 11, 2],\n",
       " [4, 11, 11, 2]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dat_encode(data,c2id)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([i[-1] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, 11,  2,  2,  2,  2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "array_uniqueYs = np.unique(Y)\n",
    "\n",
    "for uni_Y in array_uniqueYs:\n",
    "    if counter not in np.unique(Y):\n",
    "        Y[Y==uni_Y] = counter\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 7, 7],\n",
       " [10, 6, 7, 7],\n",
       " [9, 6, 7, 7],\n",
       " [5, 6, 7, 7],\n",
       " [2, 11, 11],\n",
       " [8, 11, 11],\n",
       " [1, 11, 11],\n",
       " [4, 11, 11]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all letters before to predict the last letter of each word:\n",
    "X = [i[:-1] for i in data]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 7, 7],\n",
       " [10, 6, 7, 7],\n",
       " [9, 6, 7, 7],\n",
       " [5, 6, 7, 7],\n",
       " [2, 11, 11, 0],\n",
       " [8, 11, 11, 0],\n",
       " [1, 11, 11, 0],\n",
       " [4, 11, 11, 0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post padding:\n",
    "X = [word+[0]*(max([len(i) for i in X])-len(word)) for word in X]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 13, 4)\n"
     ]
    }
   ],
   "source": [
    "#OHE:\n",
    "m = len(X) # sample size\n",
    "n = len(c2id)+1 # feature size:\n",
    "t = max([len(i) for i in X]) # time-step\n",
    "print((m,n,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mat = np.zeros((m,n,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = len(np.unique(Y))\n",
    "\n",
    "y_mat = np.zeros((m,ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Modeling:\n",
    "\n",
    "for row in range(m):\n",
    "    \n",
    "    word = X[row]\n",
    "    \n",
    "    for ts in range(t):\n",
    "        charidx = word[ts]\n",
    "        \n",
    "        dat_mat[row,charidx,ts] = 1\n",
    "    \n",
    "    yletteridx = Y[row]\n",
    "    \n",
    "    y_mat[row,yletteridx] = 1\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 13, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "N_HIDDEN = 10\n",
    "LEARNING_RATE = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxa:(13, 10)\n",
      "Waa:(10, 10)\n",
      "Way:(10, 2)\n",
      "ba:(1, 10)\n",
      "by:(1, 2)\n",
      "a0:(8, 10)\n",
      "a:(8, 10, 4)\n",
      "y_pred:(8, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Weight Matrix:\n",
    "np.random.seed(0)\n",
    "Wxa = 2*np.random.random((n,N_HIDDEN))-1\n",
    "print(\"Wxa:{}\".format(Wxa.shape))\n",
    "\n",
    "Waa = 2*np.random.random((N_HIDDEN,N_HIDDEN))-1\n",
    "print(\"Waa:{}\".format(Waa.shape))\n",
    "\n",
    "\n",
    "Way = 2*np.random.random((N_HIDDEN,ny))-1\n",
    "print(\"Way:{}\".format(Way.shape))\n",
    "\n",
    "\n",
    "ba = np.zeros((1,N_HIDDEN))\n",
    "print(\"ba:{}\".format(ba.shape))\n",
    "\n",
    "by = np.zeros((1,ny))\n",
    "print(\"by:{}\".format(by.shape))\n",
    "\n",
    "a0 = 2*np.random.random((m,N_HIDDEN))-1\n",
    "print(\"a0:{}\".format(a0.shape))\n",
    "\n",
    "a = 2*np.random.random((m,N_HIDDEN,t))-1\n",
    "print(\"a:{}\".format(a.shape))\n",
    "\n",
    "\n",
    "y_pred = 2*np.random.random((m,ny,t))-1\n",
    "print(\"y_pred:{}\".format(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'Wxa':Wxa,\n",
    "    'Waa':Waa,\n",
    "    'Way':Way,\n",
    "    'ba':ba,\n",
    "    'by':by\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Predicted:[0 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 10\n",
      "Predicted:[0 0 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 20\n",
      "Predicted:[0 0 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 30\n",
      "Predicted:[0 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 40\n",
      "Predicted:[0 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 50\n",
      "Predicted:[0 0 1 0 0 1 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 60\n",
      "Predicted:[0 0 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 70\n",
      "Predicted:[0 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 80\n",
      "Predicted:[0 0 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 90\n",
      "Predicted:[0 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 100\n",
      "Predicted:[1 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 110\n",
      "Predicted:[1 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 120\n",
      "Predicted:[1 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 130\n",
      "Predicted:[1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 140\n",
      "Predicted:[1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 150\n",
      "Predicted:[1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 160\n",
      "Predicted:[1 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 170\n",
      "Predicted:[1 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 180\n",
      "Predicted:[1 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n",
      "Epoch 190\n",
      "Predicted:[1 1 1 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 0 0 0 0]\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(N_EPOCHS): # error after 10\n",
    "    \n",
    "    \n",
    "    a_prev = a0\n",
    "    caches = []\n",
    "    overall_error = 0\n",
    "\n",
    "    \n",
    "    ##### Forward Propagate #####\n",
    "    # initialization of  gradients\n",
    "    dx = np.zeros((dat_mat.shape))#6-14-4  #m-n-t\n",
    "    dWxa = np.zeros(Wxa.shape)\n",
    "    dWaa = np.zeros(Waa.shape)\n",
    "    dWay = np.zeros(Way.shape)\n",
    "    dba = np.zeros(ba.shape)\n",
    "    dby = np.zeros(by.shape)\n",
    "    da0 = np.zeros(a0.shape)\n",
    "    da = np.zeros(a.shape)\n",
    "    da_prevt = np.zeros(a0.shape)\n",
    "\n",
    "\n",
    "    layer_2_deltas = np.zeros((m,ny,t))\n",
    "\n",
    "    \n",
    "    print_error = 0\n",
    "    for ts in range(t):\n",
    "        # a-state, passing to next t-step\n",
    "        a_next = np.tanh(np.dot(dat_mat[:,:,ts],Wxa) + np.dot(a_prev,Waa) + ba)  # m-hidden\n",
    "        a[:,:,ts] = a_next\n",
    "        # prediction of current time step:\n",
    "        yt_pred = softmax(np.dot(a_next,Way)+by)\n",
    "        y_pred[:,:,ts] = yt_pred  \n",
    "        # save a for next t-step\n",
    "        a_prev = a_next\n",
    "        # cost of current t-step:\n",
    "        cost = y_mat-yt_pred\n",
    "        # output layer error rate : error* dtanh()\n",
    "        layer_2_delta=cost*d_tanh(yt_pred)\n",
    "        layer_2_deltas[:,:,ts] = layer_2_delta #6-14\n",
    "        print_error+=cost\n",
    "        cache = (a_next, a_prev, dat_mat[:,:,ts], parameters)\n",
    "        caches.append(cache)\n",
    "        #######################\n",
    "    \n",
    "    \n",
    "    if i%10==0:\n",
    "        print('Epoch {}'.format(i))\n",
    "        all_error.append(np.sum(np.abs(y_mat-yt_pred)))\n",
    "        print_pred = np.argmax(yt_pred,axis=-1)\n",
    "        print(\"Predicted:{}\".format(print_pred))\n",
    "        print(\"Actual:{}\".format(np.argmax(y_mat,axis=-1)))\n",
    "        print('=====================')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # Prepare:\n",
    "    #Get pars from f-prop:\n",
    "    (a1, a0, x1, parameters) = caches[0]\n",
    "    # initialize:\n",
    "    next_delta = np.zeros((m,N_HIDDEN))\n",
    "    # Figure out how to get Da\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Back Propagate:\n",
    "    for ts in reversed(range(t)):\n",
    "        cache = caches[ts]\n",
    "        (a_now, a_prev, x_now, parameters) = cache\n",
    "        Wxa = parameters[\"Wxa\"]\n",
    "        Waa = parameters[\"Waa\"]\n",
    "        Way = parameters[\"Way\"]\n",
    "        ba = parameters[\"ba\"]\n",
    "        by = parameters[\"by\"]\n",
    "        # y_pred error rate\n",
    "        layer_2_delta = layer_2_deltas[:,:,ts]\n",
    "        # propagate back:\n",
    "#         if ts ==t-1:\n",
    "        da_now = (np.dot(next_delta,Waa) +  np.dot(layer_2_delta,Way.T))*d_tanh(a_now)\n",
    "#         else:\n",
    "#             da_now = np.dot(next_delta,Waa)**d_tanh(a_now)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        dWayt = np.dot(a_now.T,layer_2_delta)\n",
    "        dWaat = np.dot( da_now.T,a_prev) #20-20\n",
    "        dWxat = np.dot(x_now.T,da_now) # 14-20\n",
    "        dbat = np.sum( d_tanh(a_now),keepdims=True,axis=0)\n",
    "        next_delta = da_now\n",
    "        dxt = np.dot(da_now,Wxa.T)#6-14\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        dWxa += dWxat\n",
    "        dWaa += dWaat\n",
    "        dWay += dWayt\n",
    "        dba += dbat\n",
    "\n",
    "\n",
    "    # Gradient Clipping to avoid Gradient Exploding:\n",
    "    dWxa = np.clip(dWxa,-50,50)\n",
    "    dWaa = np.clip(dWaa,-50,50)\n",
    "    dWay = np.clip(dWay,-50,50)\n",
    "    dba = np.clip(dba,-50,50)\n",
    "\n",
    "\n",
    "    # Updating\n",
    "    Wxa+=LEARNING_RATE*dWxa\n",
    "    Waa+=LEARNING_RATE*dWaa\n",
    "    Way+=LEARNING_RATE*dWay\n",
    "    ba+=LEARNING_RATE*dba\n",
    "\n",
    "    # resetting\n",
    "    dWxat *= 0 \n",
    "    dWaat *= 0\n",
    "    dWayt *= 0  \n",
    "    dbat  *= 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "As we training more than 130 Epochs, the model is able to get 100% in sample accuracy.\n",
    "Again this is only a vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
