{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN Implementation\n",
    "\n",
    "- with tanh activation\n",
    "\n",
    "- with gradient clipping\n",
    "\n",
    "### Author: Yifan Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Helper Functions:\n",
    "def d_tanh(x):\n",
    "\n",
    "    return 1 - np.tanh(x)*np.tanh(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''Softmax'''\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1,keepdims=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_softmax(x):\n",
    "    J = x[..., None] * x[:, None, :]\n",
    "    iy, ix = np.diag_indices_from(J[0])\n",
    "    J[:, iy, ix] = x * (1. - x)\n",
    "    return J.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally at each time step of forward, we do:\n",
    "\n",
    "    a_now = activation_relu(Waa * a_previous + Wax * X_now  + ba)\n",
    "    y_hat = sigmoid(activation_relu(Wya*a_now + by))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    'hello',\n",
    "    'halo',\n",
    "    'jello',\n",
    "    'kello',\n",
    "    'yello',\n",
    "    'noon',\n",
    "    'moon',\n",
    "    'soon',\n",
    "    'zoon',\n",
    "    'ten'\n",
    "]\n",
    "data = [list(word) for word in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 7,\n",
       " 'e': 13,\n",
       " 'h': 9,\n",
       " 'j': 2,\n",
       " 'k': 12,\n",
       " 'l': 3,\n",
       " 'm': 11,\n",
       " 'n': 4,\n",
       " 'o': 10,\n",
       " 's': 5,\n",
       " 't': 6,\n",
       " 'y': 1,\n",
       " 'z': 8}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict:\n",
    "c2id = {v:k+1 for k,v in enumerate(set([j for i in data for j in i]))}\n",
    "c2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2id[''] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding:\n",
    "def dat_encode(data,c2id):\n",
    "    new_data =[]\n",
    "    for word in data:\n",
    "        new_word = []\n",
    "        for char in word:\n",
    "            new_word.append(c2id[char])\n",
    "        new_data.append(new_word)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 13, 3, 3, 10],\n",
       " [9, 7, 3, 10],\n",
       " [2, 13, 3, 3, 10],\n",
       " [12, 13, 3, 3, 10],\n",
       " [1, 13, 3, 3, 10],\n",
       " [4, 10, 10, 4],\n",
       " [11, 10, 10, 4],\n",
       " [5, 10, 10, 4],\n",
       " [8, 10, 10, 4],\n",
       " [6, 13, 4]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dat_encode(data,c2id)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([i[-1] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10, 10,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "array_uniqueYs = np.unique(Y)\n",
    "\n",
    "for uni_Y in array_uniqueYs:\n",
    "    if counter not in np.unique(Y):\n",
    "        Y[Y==uni_Y] = counter\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 13, 3, 3],\n",
       " [9, 7, 3],\n",
       " [2, 13, 3, 3],\n",
       " [12, 13, 3, 3],\n",
       " [1, 13, 3, 3],\n",
       " [4, 10, 10],\n",
       " [11, 10, 10],\n",
       " [5, 10, 10],\n",
       " [8, 10, 10],\n",
       " [6, 13]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use all letters before to predict the last letter of each word:\n",
    "X = [i[:-1] for i in data]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 13, 3, 3],\n",
       " [9, 7, 3, 0],\n",
       " [2, 13, 3, 3],\n",
       " [12, 13, 3, 3],\n",
       " [1, 13, 3, 3],\n",
       " [4, 10, 10, 0],\n",
       " [11, 10, 10, 0],\n",
       " [5, 10, 10, 0],\n",
       " [8, 10, 10, 0],\n",
       " [6, 13, 0, 0]]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post padding:\n",
    "X = [word+[0]*(max([len(i) for i in X])-len(word)) for word in X]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 15, 4)\n"
     ]
    }
   ],
   "source": [
    "#OHE:\n",
    "m = len(X) # sample size\n",
    "n = len(c2id)+1 # feature size:\n",
    "t = max([len(i) for i in X]) # time-step\n",
    "print((m,n,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mat = np.zeros((m,n,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = len(np.unique(Y))\n",
    "\n",
    "y_mat = np.zeros((m,ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Modeling:\n",
    "\n",
    "for row in range(m):\n",
    "    \n",
    "    word = X[row]\n",
    "    \n",
    "    for ts in range(t):\n",
    "        charidx = word[ts]\n",
    "        \n",
    "        dat_mat[row,charidx,ts] = 1\n",
    "    \n",
    "    yletteridx = Y[row]\n",
    "    \n",
    "    y_mat[row,yletteridx] = 1\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15, 4)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1000\n",
    "N_HIDDEN = 50\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxa:(15, 50)\n",
      "Waa:(50, 50)\n",
      "Way:(50, 2)\n",
      "ba:(1, 50)\n",
      "by:(1, 2)\n",
      "a0:(10, 50)\n",
      "a:(10, 50, 4)\n",
      "y_pred:(10, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Weight Matrix:\n",
    "np.random.seed(0)\n",
    "Wxa = 2*np.random.random((n,N_HIDDEN))-1\n",
    "print(\"Wxa:{}\".format(Wxa.shape))\n",
    "\n",
    "Waa = 2*np.random.random((N_HIDDEN,N_HIDDEN))-1\n",
    "print(\"Waa:{}\".format(Waa.shape))\n",
    "\n",
    "\n",
    "Way = 2*np.random.random((N_HIDDEN,ny))-1\n",
    "print(\"Way:{}\".format(Way.shape))\n",
    "\n",
    "\n",
    "ba = np.zeros((1,N_HIDDEN))\n",
    "print(\"ba:{}\".format(ba.shape))\n",
    "\n",
    "by = np.zeros((1,ny))\n",
    "print(\"by:{}\".format(by.shape))\n",
    "\n",
    "a0 = 2*np.random.random((m,N_HIDDEN))-1\n",
    "print(\"a0:{}\".format(a0.shape))\n",
    "\n",
    "a = 2*np.random.random((m,N_HIDDEN,t))-1\n",
    "print(\"a:{}\".format(a.shape))\n",
    "\n",
    "\n",
    "y_pred = 2*np.random.random((m,ny,t))-1\n",
    "print(\"y_pred:{}\".format(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'Wxa':Wxa,\n",
    "    'Waa':Waa,\n",
    "    'Way':Way,\n",
    "    'ba':ba,\n",
    "    'by':by\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Predicted:[1 0 1 1 0 0 0 1 1 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:6.1618266663963945\n",
      "=====================\n",
      "Epoch 10\n",
      "Predicted:[0 0 0 0 0 0 1 0 1 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:13.086877401232588\n",
      "=====================\n",
      "Epoch 20\n",
      "Predicted:[0 0 1 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:5.709503980596753\n",
      "=====================\n",
      "Epoch 30\n",
      "Predicted:[0 0 0 0 0 0 0 0 1 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.618305524879649\n",
      "=====================\n",
      "Epoch 40\n",
      "Predicted:[1 0 0 0 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:7.192302815048875\n",
      "=====================\n",
      "Epoch 50\n",
      "Predicted:[0 0 1 0 0 1 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:10.847579227927024\n",
      "=====================\n",
      "Epoch 60\n",
      "Predicted:[0 0 0 0 0 1 1 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:11.58851505394955\n",
      "=====================\n",
      "Epoch 70\n",
      "Predicted:[0 1 0 0 1 1 1 1 1 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:11.447234965318613\n",
      "=====================\n",
      "Epoch 80\n",
      "Predicted:[1 0 1 1 1 1 1 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.862987382218874\n",
      "=====================\n",
      "Epoch 90\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.7936623195593\n",
      "=====================\n",
      "Epoch 100\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:10.323718225628102\n",
      "=====================\n",
      "Epoch 110\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.940985121763626\n",
      "=====================\n",
      "Epoch 120\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.859601741939304\n",
      "=====================\n",
      "Epoch 130\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.873967200120834\n",
      "=====================\n",
      "Epoch 140\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.897263288772322\n",
      "=====================\n",
      "Epoch 150\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.922882752902167\n",
      "=====================\n",
      "Epoch 160\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.892219795652819\n",
      "=====================\n",
      "Epoch 170\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.829877739229438\n",
      "=====================\n",
      "Epoch 180\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.808991614110589\n",
      "=====================\n",
      "Epoch 190\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.762016176011041\n",
      "=====================\n",
      "Epoch 200\n",
      "Predicted:[1 1 1 1 1 1 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.593773817964124\n",
      "=====================\n",
      "Epoch 210\n",
      "Predicted:[1 1 1 1 1 0 0 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:8.019391374681431\n",
      "=====================\n",
      "Epoch 220\n",
      "Predicted:[1 1 1 1 1 0 1 1 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:8.670383702968305\n",
      "=====================\n",
      "Epoch 230\n",
      "Predicted:[1 0 1 1 1 1 1 1 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:9.150119209228478\n",
      "=====================\n",
      "Epoch 240\n",
      "Predicted:[0 0 0 0 1 0 1 1 0 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:12.782324305899227\n",
      "=====================\n",
      "Epoch 250\n",
      "Predicted:[1 1 1 1 1 1 1 0 1 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:7.019999661256961\n",
      "=====================\n",
      "Epoch 260\n",
      "Predicted:[1 1 1 1 1 0 0 0 1 1]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:6.159092805891451\n",
      "=====================\n",
      "Epoch 270\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:1.7826117971617608\n",
      "=====================\n",
      "Epoch 280\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:1.2625515267780079\n",
      "=====================\n",
      "Epoch 290\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:1.0729566651014257\n",
      "=====================\n",
      "Epoch 300\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.9590130454037292\n",
      "=====================\n",
      "Epoch 310\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.8789906913423777\n",
      "=====================\n",
      "Epoch 320\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.8181090208587617\n",
      "=====================\n",
      "Epoch 330\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.7694538427035145\n",
      "=====================\n",
      "Epoch 340\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.7292575736755499\n",
      "=====================\n",
      "Epoch 350\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.6952365083643415\n",
      "=====================\n",
      "Epoch 360\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.6309023665086012\n",
      "=====================\n",
      "Epoch 370\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.548469026045451\n",
      "=====================\n",
      "Epoch 380\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.45168768441156815\n",
      "=====================\n",
      "Epoch 390\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.3762124223564662\n",
      "=====================\n",
      "Epoch 400\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.3426800042772344\n",
      "=====================\n",
      "Epoch 410\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.3308715200355313\n",
      "=====================\n",
      "Epoch 420\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.32098492798838985\n",
      "=====================\n",
      "Epoch 430\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.3121812659592684\n",
      "=====================\n",
      "Epoch 440\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.3041913804844978\n",
      "=====================\n",
      "Epoch 450\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.29686637802033505\n",
      "=====================\n",
      "Epoch 460\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.29010775987106757\n",
      "=====================\n",
      "Epoch 470\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2838429562184645\n",
      "=====================\n",
      "Epoch 480\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.27801467510567857\n",
      "=====================\n",
      "Epoch 490\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.27257569449005514\n",
      "=====================\n",
      "Epoch 500\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2674860376582408\n",
      "=====================\n",
      "Epoch 510\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.26271128032679963\n",
      "=====================\n",
      "Epoch 520\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.25822144082847714\n",
      "=====================\n",
      "Epoch 530\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.25399019721247046\n",
      "=====================\n",
      "Epoch 540\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.24999430330413336\n",
      "=====================\n",
      "Epoch 550\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.24621313503234432\n",
      "=====================\n",
      "Epoch 560\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.24262832734637618\n",
      "=====================\n",
      "Epoch 570\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.23922347716981857\n",
      "=====================\n",
      "Epoch 580\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.23598389626059324\n",
      "=====================\n",
      "Epoch 590\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.23289640284675608\n",
      "=====================\n",
      "Epoch 600\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.22994914405649014\n",
      "=====================\n",
      "Epoch 610\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.22713144324472184\n",
      "=====================\n",
      "Epoch 620\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.22443366775466272\n",
      "=====================\n",
      "Epoch 630\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.22184711367309648\n",
      "=====================\n",
      "Epoch 640\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2193639048810468\n",
      "=====================\n",
      "Epoch 650\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2169769042520658\n",
      "=====================\n",
      "Epoch 660\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2146796352646481\n",
      "=====================\n",
      "Epoch 670\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.21246621261098492\n",
      "=====================\n",
      "Epoch 680\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.2103312806278607\n",
      "=====================\n",
      "Epoch 690\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.20826995856585484\n",
      "=====================\n",
      "Epoch 700\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.20627779186369938\n",
      "=====================\n",
      "Epoch 710\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.20435070871569197\n",
      "=====================\n",
      "Epoch 720\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.20248498131864331\n",
      "=====================\n",
      "Epoch 730\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.20067719126624622\n",
      "=====================\n",
      "Epoch 740\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.198924198626843\n",
      "=====================\n",
      "Epoch 750\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1972231142981596\n",
      "=====================\n",
      "Epoch 760\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.19557127528169305\n",
      "=====================\n",
      "Epoch 770\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.19396622256163815\n",
      "=====================\n",
      "Epoch 780\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.19240568130972754\n",
      "=====================\n",
      "Epoch 790\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.19088754316893733\n",
      "=====================\n",
      "Epoch 800\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1894098503965648\n",
      "=====================\n",
      "Epoch 810\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18797078167111167\n",
      "=====================\n",
      "Epoch 820\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18656863938847976\n",
      "=====================\n",
      "Epoch 830\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18520183829133896\n",
      "=====================\n",
      "Epoch 840\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18386889529178588\n",
      "=====================\n",
      "Epoch 850\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18256842036175294\n",
      "=====================\n",
      "Epoch 860\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18129910837835897\n",
      "=====================\n",
      "Epoch 870\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.18005973182276214\n",
      "=====================\n",
      "Epoch 880\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1788491342412633\n",
      "=====================\n",
      "Epoch 890\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1776662243865477\n",
      "=====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.176509970965246\n",
      "=====================\n",
      "Epoch 910\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1753793979254859\n",
      "=====================\n",
      "Epoch 920\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1742735802248656\n",
      "=====================\n",
      "Epoch 930\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.17319164002551826\n",
      "=====================\n",
      "Epoch 940\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.17213274326848335\n",
      "=====================\n",
      "Epoch 950\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.1710960965847359\n",
      "=====================\n",
      "Epoch 960\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.17008094450486638\n",
      "=====================\n",
      "Epoch 970\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.16908656693354993\n",
      "=====================\n",
      "Epoch 980\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.16811227685880228\n",
      "=====================\n",
      "Epoch 990\n",
      "Predicted:[1 1 1 1 1 0 0 0 0 0]\n",
      "Actual:[1 1 1 1 1 0 0 0 0 0]\n",
      "Error:0.16715741826938466\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(N_EPOCHS): # error after 10\n",
    "    \n",
    "    \n",
    "    a_prev = a0\n",
    "    caches = []\n",
    "    overall_error = 0\n",
    "\n",
    "    \n",
    "    ##### Forward Propagate #####\n",
    "    # initialization of  gradients\n",
    "    dx = np.zeros((dat_mat.shape))#6-14-4  #m-n-t\n",
    "    dWxa = np.zeros(Wxa.shape)\n",
    "    dWaa = np.zeros(Waa.shape)\n",
    "    dWay = np.zeros(Way.shape)\n",
    "    dba = np.zeros(ba.shape)\n",
    "    dby = np.zeros(by.shape)\n",
    "    da0 = np.zeros(a0.shape)\n",
    "    da = np.zeros(a.shape)\n",
    "    da_prevt = np.zeros(a0.shape)\n",
    "\n",
    "\n",
    "    layer_2_deltas = np.zeros((m,ny,t))\n",
    "\n",
    "    \n",
    "    print_error = 0\n",
    "    for ts in range(t):\n",
    "        # a-state, passing to next t-step\n",
    "        a_next = np.tanh(np.dot(dat_mat[:,:,ts],Wxa) + np.dot(a_prev,Waa) + ba)  # m-hidden\n",
    "        a[:,:,ts] = a_next\n",
    "        # prediction of current time step:\n",
    "        yt_pred = softmax(np.dot(a_next,Way)+by)\n",
    "        y_pred[:,:,ts] = yt_pred  \n",
    "        # save a for next t-step\n",
    "        a_prev = a_next\n",
    "        # cost of current t-step:\n",
    "        cost = y_mat-yt_pred\n",
    "        # output layer error rate : error* dtanh()\n",
    "        layer_2_delta=cost*d_softmax(yt_pred)\n",
    "        layer_2_deltas[:,:,ts] = layer_2_delta #6-14\n",
    "        print_error=np.sum(np.abs(cost))\n",
    "        cache = (a_next, a_prev, dat_mat[:,:,ts], parameters)\n",
    "        caches.append(cache)\n",
    "        #######################\n",
    "    \n",
    "    all_error.append(print_error)\n",
    "    \n",
    "    if i%10==0:\n",
    "        print('Epoch {}'.format(i))\n",
    "        print_pred = np.argmax(yt_pred,axis=-1)\n",
    "        print(\"Predicted:{}\".format(print_pred))\n",
    "        print(\"Actual:{}\".format(np.argmax(y_mat,axis=-1)))\n",
    "        print(\"Error:{}\".format( print_error))\n",
    "        print('=====================')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # Prepare:\n",
    "    #Get pars from f-prop:\n",
    "    (a1, a0, x1, parameters) = caches[0]\n",
    "    # initialize:\n",
    "    next_delta = np.zeros((m,N_HIDDEN))\n",
    "    # Figure out how to get Da\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Back Propagate:\n",
    "    for ts in reversed(range(t)):\n",
    "        cache = caches[ts]\n",
    "        (a_now, a_prev, x_now, parameters) = cache\n",
    "        Wxa = parameters[\"Wxa\"]\n",
    "        Waa = parameters[\"Waa\"]\n",
    "        Way = parameters[\"Way\"]\n",
    "        ba = parameters[\"ba\"]\n",
    "        by = parameters[\"by\"]\n",
    "        # y_pred error rate\n",
    "        layer_2_delta = layer_2_deltas[:,:,ts]\n",
    "        # propagate back:\n",
    "\n",
    "        \n",
    "\n",
    "#         else:\n",
    "#             da_now = np.dot(next_delta,Waa)**d_tanh(a_now)\n",
    "\n",
    "        # update the prediction_t branch:\n",
    "        dWayt = np.dot(a_now.T,layer_2_delta)\n",
    "        \n",
    "        \n",
    "        #update the first layer: Waa, Wxa by  combining a_now and y_pred output\n",
    "        # next_delta:  delta from next_time_step's  a\n",
    "        # layer_2_delta: error rate from this time step's Y_pred\n",
    "#         if ts ==t-1:\n",
    "        da_now = (np.dot(next_delta,Waa) +  np.dot(layer_2_delta,Way.T))*d_tanh(a_now)      \n",
    "#         else: \n",
    "#             da_now = (np.dot(next_delta,Waa))*d_tanh(a_now) \n",
    "            \n",
    "            \n",
    "        dWaat = np.dot( da_now.T,a_prev) #20-20\n",
    "        dWxat = np.dot(x_now.T,da_now) # 14-20\n",
    "        dbat = np.sum( d_tanh(a_now),keepdims=True,axis=0)\n",
    "        next_delta = da_now\n",
    "        dxt = np.dot(da_now,Wxa.T)#6-14\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        dWxa += dWxat\n",
    "        dWaa += dWaat\n",
    "        dWay += dWayt\n",
    "        dba += dbat\n",
    "\n",
    "\n",
    "    # Gradient Clipping to avoid Gradient Exploding:\n",
    "    dWxa = np.clip(dWxa,-50,50)\n",
    "    dWaa = np.clip(dWaa,-50,50)\n",
    "    dWay = np.clip(dWay,-50,50)\n",
    "    dba = np.clip(dba,-50,50)\n",
    "\n",
    "\n",
    "    # Updating\n",
    "    Wxa+=LEARNING_RATE*dWxa\n",
    "    Waa+=LEARNING_RATE*dWaa\n",
    "    Way+=LEARNING_RATE*dWay\n",
    "    ba+=LEARNING_RATE*dba\n",
    "\n",
    "    # resetting\n",
    "    dWxat *= 0 \n",
    "    dWaat *= 0\n",
    "    dWayt *= 0  \n",
    "    dbat  *= 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10913d588>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10932b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
