{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Implementation\n",
    "(with K-means++ initialization)\n",
    "### Author: Yifan Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.datasets import load_digits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_digits(n_class = 3, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 64)\n",
      "(537,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMEANS:\n",
    "    def __init__(self, k, iters=100,n_eval=10):\n",
    "        '''\n",
    "        Input:\n",
    "        k: number of clusters\n",
    "        iters: number of iterations the model will run\n",
    "        n_eval: evaluate the Within-cluster sum of squares every how many rounds\n",
    "        '''\n",
    "        self.k = k\n",
    "        self.iters = iters\n",
    "        self.n_eval = n_eval\n",
    "        \n",
    "    def distance(self, data,centroid):\n",
    "        '''vectorized euclidean distance\n",
    "\n",
    "        Input:\n",
    "        data: X matrix for the Kmeans, dimension is mxn\n",
    "        centroid: centroid matrix, dimension is kxn\n",
    "\n",
    "        Note: np.newaxis is used to broadcast vectorized operations\n",
    "        '''\n",
    "\n",
    "        return np.sqrt((np.square(data[:,np.newaxis]-centroid).sum(axis=2))) \n",
    "\n",
    "\n",
    "    def centroids_init(self,X,k):\n",
    "        '''\n",
    "        K-means++ centroid initialzation method.\n",
    "        Details can be found: https://en.wikipedia.org/wiki/K-means%2B%2B\n",
    "        Steps:\n",
    "\n",
    "\n",
    "            1. Choose one center uniformly at random from among the data points.\n",
    "            2. For each data point x, compute D(x), the distance between x and the nearest center that has already been chosen.\n",
    "            3. Choose one new data point at random as a new center, using a weighted probability distribution where a point x is chosen with probability proportional to D(x)2.\n",
    "            4. Repeat Steps 2 and 3 until k centers have been chosen.\n",
    "        Now that the initial centers have been chosen, proceed using standard k-means clustering.\n",
    "        '''\n",
    "        dim = X.shape[1]\n",
    "        centroids = np.zeros((k,dim))\n",
    "        # first centroid:\n",
    "        centroids[0,:] = X[np.random.randint(X.shape[0]),]\n",
    "        # subsequent centroid:\n",
    "        for i in range(1,k):\n",
    "            sq_dist = distance(X, centroids[i-1,:].reshape(1,-1))**2\n",
    "            prob = sq_dist/np.sum(sq_dist)\n",
    "            cent_idx = np.random.choice(range(X.shape[0]),p = prob.ravel())\n",
    "            centroids[i,:] = X[cent_idx,]\n",
    "\n",
    "        return centroids\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self,X):\n",
    "        centroids_mat = self.centroids_init(X,self.k)\n",
    "        \n",
    "        for round in range(self.iters):\n",
    "            dists = self.distance(X,centroids_mat) # distance calc\n",
    "            labels = np.argmin(dists,axis=1) # cluster labeling based on distances\n",
    "\n",
    "            if round%self.n_eval==0:\n",
    "                print(\"Within-Cluster Sum of Squares: {}\".format(np.sum(np.min(dists,axis=1))))\n",
    "\n",
    "            # Re-adjust centroid:\n",
    "            if round < (self.iters-1):\n",
    "                for i in range(self.k):\n",
    "                    centroids_mat[i,:] = np.mean(X[labels==i,:],axis=0)\n",
    "        self.cluster = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTER = 3\n",
    "N_ITER = 150\n",
    "N_EVAL =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model = KMEANS(\n",
    "    k = N_CLUSTER, \n",
    "    iters=N_ITER,\n",
    "    n_eval=N_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize scale:\n",
    "X /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-Cluster Sum of Squares: 82.4121597722791\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n",
      "Within-Cluster Sum of Squares: 52.74963388979773\n"
     ]
    }
   ],
   "source": [
    "km_model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "\n",
    "Let's check within each cluster, what are the actual digits labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all data labeled 0 :\n",
      "The label:count pairs are: Counter({0: 178, 2: 3, 1: 2})\n",
      "For all data labeled 1 :\n",
      "The label:count pairs are: Counter({1: 153, 2: 9})\n",
      "For all data labeled 2 :\n",
      "The label:count pairs are: Counter({2: 165, 1: 27})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for cl in range(N_CLUSTER):\n",
    "    \n",
    "    idx = km_model.cluster==cl\n",
    "    \n",
    "    res = Counter(y[idx])\n",
    "    \n",
    "    \n",
    "    print('For all data labeled %d :'%cl)\n",
    "    print('The label:count pairs are: {}'.format(res))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "According to the result, \n",
    "\n",
    "- In the first cluster,  178/183 = 97%   are belong to the same label;\n",
    "- In the second cluster, 153/162 = 94%   are belong to the same label;\n",
    "- In the third cluster,  165/192 = 85%   are belong to the same label;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-means_clustering\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-means%2B%2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
