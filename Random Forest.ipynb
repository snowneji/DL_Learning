{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Random Forest with Parallel Processing\n",
    "\n",
    "\n",
    "### Author: Yifan Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second part of series of decision tree tutorial implementations by Yifan Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import multiprocessing as mp\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class id3_tree():\n",
    "    'Implementation of ID3 Decision Tree in Python, majorly in NumPy'\n",
    "    def __init__(self,least_children_num,verbose=True):\n",
    "        self.least_children_num = least_children_num\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    \n",
    "    def fit(self,tmp_x,tmp_y):\n",
    "        def fit_tree(tmp_x,tmp_y):\n",
    "        #     Exit Condition 0:\n",
    "            # Exit Condition 1:\n",
    "            if \\\n",
    "            len(tmp_y) < self.least_children_num or len(np.unique(tmp_y))==1:\n",
    "\n",
    "                if self.verbose:\n",
    "                    print('exit condition:')\n",
    "                    print('tmp_y:')\n",
    "                    print(tmp_y)\n",
    "\n",
    "                mode_val = self.mode(tmp_y.flatten().tolist())\n",
    "                return([np.nan, mode_val, np.nan, np.nan]) # Leaf Node: format [feat,splitval,]\n",
    "\n",
    "            # Otherwise Split:\n",
    "            if self.verbose:\n",
    "                print(\"start....subset Y len {}\".format(len(tmp_y)))\n",
    "\n",
    "\n",
    "            split_row,split_col = self.decide_split_data(tmp_x,tmp_y)\n",
    "\n",
    "            if not split_row and not split_col:\n",
    "#                 print('no better split...return mode')\n",
    "                mode_val = self.mode(tmp_y.flatten().tolist())\n",
    "                return([np.nan, mode_val, np.nan, np.nan])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"split on:\")\n",
    "                print(split_row,split_col)\n",
    "\n",
    "\n",
    "            split_vec = tmp_x[:,split_col]\n",
    "            split_val = tmp_x[split_row,split_col]\n",
    "\n",
    "            # Recursively Split to left and right branches:\n",
    "            left_ind = np.where(split_vec<split_val)[0].tolist()\n",
    "            right_ind = np.where(split_vec>=split_val)[0].tolist()\n",
    "            left_dat,left_y = tmp_x[left_ind,:],tmp_y[left_ind,]\n",
    "            right_dat,right_y = tmp_x[right_ind,:],tmp_y[right_ind,]\n",
    "\n",
    "            left_tree = fit_tree(left_dat,left_y)\n",
    "            right_tree = fit_tree(right_dat,right_y)\n",
    "\n",
    "            if isinstance(left_tree, list): # If list, tree len 1\n",
    "                len_l_tree = 1\n",
    "            else:\n",
    "                len_l_tree = left_tree.shape[0] # If array, tree len >1\n",
    "\n",
    "            root = [split_col,split_val,1,len_l_tree+1] # Format [split_col, split_val, left_tree_relative_idx, right_tree_relative_idx]\n",
    "            return(np.vstack([root,left_tree,right_tree]))\n",
    "        \n",
    "        tree = fit_tree(tmp_x,tmp_y)\n",
    "        self.tree = tree\n",
    "\n",
    "    \n",
    "\n",
    "    def decide_split_data(self,x,y):\n",
    "        'Given subset of X,Y, search for the best splitting node based on: information gain'\n",
    "        def entropy(tmp_y):\n",
    "            'Key Metrics of building a decision tree. Specifically Shannon Entropy'\n",
    "            tmp_ent = 0\n",
    "            for uni_y in np.unique(tmp_y):\n",
    "                p = len(tmp_y[tmp_y==uni_y])/len(tmp_y)\n",
    "                tmp_ent -= (p*np.log2(p))\n",
    "            return tmp_ent\n",
    "\n",
    "        m,n = x.shape\n",
    "        best_gain = 0\n",
    "        split_row, split_col = None,None\n",
    "\n",
    "        previous_entropy = entropy(y)\n",
    "        for col in range(n):\n",
    "            tmp_vec = x[:,col].ravel()\n",
    "\n",
    "            for row in range(m):\n",
    "                val = tmp_vec[row]\n",
    "                # >= & < is my convention here:\n",
    "                if val!=np.max(tmp_vec) and val!= np.min(tmp_vec):\n",
    "                    left_b = np.where(tmp_vec<val)[0].tolist()\n",
    "                    right_b = np.where(tmp_vec>=val)[0].tolist()\n",
    "\n",
    "                    # new entropy is the weighted  average entropy from each of the subset\n",
    "                    new_ent = \\\n",
    "                    (len(y[left_b])/len(y))*entropy(y[left_b]) + \\\n",
    "                    (len(y[right_b])/len(y))*entropy(y[right_b])\n",
    "\n",
    "\n",
    "    #                 print('new entropy: %f'%new_ent)\n",
    "                    info_gain = previous_entropy - new_ent\n",
    "\n",
    "                    if info_gain > best_gain:\n",
    "                        split_row, split_col = row,col\n",
    "                        best_gain = info_gain\n",
    "                        if self.verbose:\n",
    "                            print('better gain:{}'.format(best_gain))\n",
    "                            print()\n",
    "\n",
    "        return split_row, split_col\n",
    "                \n",
    "                \n",
    "\n",
    "    def mode(self, x_list):\n",
    "        'calculate the mode'\n",
    "        return Counter(x_list).most_common(1)[0][0]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, tmp_test_array):\n",
    "        'Wrap-up fun for prediction'\n",
    "        def query(tree,tmp_test_array):\n",
    "            'Test for single example'\n",
    "            assert len(tmp_test_array.shape) == 2, \"Make sure your test data is 2d array\"\n",
    "\n",
    "\n",
    "            if isinstance(tree,list):\n",
    "                start_node = tree # only the 1 row in data\n",
    "            else:\n",
    "                start_node = tree[0,:] # Iteratively hit first row\n",
    "   \n",
    "            test_feat,test_val,left_tree_jump,right_tree_jump = start_node[0],start_node[1],start_node[2],start_node[3]\n",
    "\n",
    "            # Exit Condition:\n",
    "            if np.isnan(test_feat) and np.isnan(left_tree_jump) and np.isnan(right_tree_jump):\n",
    "                pred = test_val;\n",
    "                return pred \n",
    "            #Test:\n",
    "            if tmp_test_array[0,int(test_feat)] < test_val:\n",
    "                # If <, go left branch:\n",
    "                jump_loc = left_tree_jump\n",
    "                pred = query(tree[int(jump_loc):,],tmp_test_array)\n",
    "\n",
    "            else:\n",
    "                # If >=, go right branch:\n",
    "                jump_loc = right_tree_jump\n",
    "                pred = query(tree[int(jump_loc):,],tmp_test_array)\n",
    "\n",
    "            return pred\n",
    "\n",
    "        assert len(tmp_test_array.shape) == 2, \"Make sure your test data is 2d array\"\n",
    "        result = []\n",
    "\n",
    "        for i in range(tmp_test_array.shape[0]):\n",
    "            inp = tmp_test_array[i,:].reshape(1,-1)\n",
    "            result.append(query(self.tree,inp))\n",
    "        return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassification():\n",
    "    'Python inplementation of random forest classifier using id3 as the base tree'\n",
    "    def __init__ (\n",
    "        self,\n",
    "        n_tree,\n",
    "        min_leaf_num,  # to control overfit\n",
    "        criteria = 'entropy', # currently only support entropy\n",
    "        max_features = 'auto',# if max_feature = sqrt(number of features), otherwise will be proportion of features sampled\n",
    "        n_workers = 1,\n",
    "        verbose = True\n",
    "        \n",
    "    ):\n",
    "        self.n_tree = n_tree\n",
    "        self.min_leaf_num = min_leaf_num\n",
    "        self.criteria = criteria\n",
    "        self.max_features = max_features\n",
    "        self.n_workers = n_workers\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit_single(self,data):\n",
    "        \n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "        tmp_X,tmp_y,feat_choose = self.random_find_feature(X,y)\n",
    "#         tmp_X,tmp_y = X,y\n",
    "        model = id3_tree(least_children_num = self.min_leaf_num,verbose=False)\n",
    "        model.fit(tmp_X,tmp_y)\n",
    "        return model,feat_choose\n",
    "\n",
    "    \n",
    "    def fit_rf(self,X,y):\n",
    "#         model_list = []\n",
    "        data = [X,y]\n",
    "        with mp.Pool(self.n_workers) as p:\n",
    "            model_list = p.map(self.fit_single,[data]*self.n_tree)\n",
    "            \n",
    "        self.model_list = model_list\n",
    "        \n",
    "#         for i in range(self.n_tree):\n",
    "#             print(i)\n",
    "#             single_model,single_feat_choose = self.fit_single(data)\n",
    "            \n",
    "            \n",
    "#             model_list.append((single_model,single_feat_choose))\n",
    "#         self.model_list = model_list\n",
    "        \n",
    "    def predict_rf(self,X):\n",
    "        print(\"start_prediction\")\n",
    "        result_list = []\n",
    "        for model_stuff in self.model_list:\n",
    "            single_model,single_feat_choose = model_stuff\n",
    "            \n",
    "            res = single_model.predict(X[:,single_feat_choose])\n",
    "            result_list.append(res)\n",
    "            \n",
    "        return scipy.stats.mode(np.array(result_list),axis=0).mode.tolist()[0] # Take the vote\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def random_find_feature(self,X,y):\n",
    "        'Randomly select subset of features for each tree'\n",
    "        \n",
    "        if self.max_features == 'auto':\n",
    "            n_feat_dat = X.shape[1]\n",
    "            n_feat_choose = int(round(np.sqrt(n_feat_dat)))\n",
    "        else:\n",
    "            n_feat_dat = X.shape[1]\n",
    "            n_feat_choose = int(n_feat_dat*self.max_features)\n",
    "            \n",
    "        feat_choose = np.random.choice(range(n_feat_dat),size=n_feat_choose,replace=False).tolist()\n",
    "        feat_choose = sorted(feat_choose) # Important to sort this in order otherwise will confuse the model\n",
    "#         print(\"feat_chosen:{}\".format(feat_choose))\n",
    "\n",
    "\n",
    "        return  X[:,feat_choose],y,feat_choose\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using 113 validation examples\n"
     ]
    }
   ],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# shuffling:\n",
    "idx = [i for i in range(len(y))]\n",
    "np.random.seed(1028)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "\n",
    "# 20% Data For validation:\n",
    "val_ratio = 0.2\n",
    "val_num = int(len(y)*val_ratio)\n",
    "\n",
    "print(\"We will be using {} validation examples\".format(val_num))\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_valid = X[val_num:], X[:val_num]\n",
    "\n",
    "y_train,y_valid = y[val_num:], y[:val_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 30)\n",
      "(113, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassification(\n",
    "    n_tree=100,\n",
    "    min_leaf_num=2,\n",
    "    verbose=True,\n",
    "    n_workers = 4,\n",
    "    max_features = 0.5\n",
    "    \n",
    ")\n",
    "model3.fit_rf(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_prediction\n"
     ]
    }
   ],
   "source": [
    "pred = model3.predict_rf(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911504424778761"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy Function:\n",
    "accuracy = lambda pred,y:   float(sum([pred[i]==y[i] for i in range(len(y))])) / len(y)\n",
    "\n",
    "\n",
    "y_valid_list = y_valid.tolist()\n",
    "accuracy(pred,y_valid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember in the previous tutorial, ID3 Single Tree got 90% of accuracy, now using random forest, we boosted out accuracy to 91.15%\n",
    "\n",
    "\n",
    "All Hail to The Forest Master!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: \n",
    "\n",
    "* Gradient Boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
