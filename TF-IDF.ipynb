{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TF-IDF Implementation\n",
    "\n",
    "#### Author: Yifan Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# TFIDF Algorithm\n",
    "class TFIDF(object):\n",
    "    \n",
    "    def __init__ (self, stopwords):\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "    \n",
    "        \n",
    "    def tokenizer(self,data):\n",
    "        '''tokenize text into list of words and Remove SW'''\n",
    "\n",
    "\n",
    "        data = [x.lower().split() for x in data]\n",
    "\n",
    "        # Remove Stopwords:\n",
    "        clean_data = []\n",
    "        for doc in data:\n",
    "            clean_data.append([w for w in doc if w not in self.stopwords])\n",
    "        \n",
    "        self.data = clean_data\n",
    "#         print(self.data)\n",
    "    \n",
    "    \n",
    "    def tfidf_word2id(self):\n",
    "        # Word to Index\n",
    "        new_data = []\n",
    "        word2id = {}\n",
    "        counter = 1\n",
    "        for doc in self.data:\n",
    "            new_doc = []\n",
    "            for tok in doc:\n",
    "                if tok not in word2id:\n",
    "                    word2id[tok] = str(counter)\n",
    "                    counter += 1\n",
    "\n",
    "                new_doc.append(word2id[tok])\n",
    "            new_data.append(new_doc)\n",
    "\n",
    "        self.word2id = word2id\n",
    "        self.data = new_data\n",
    "\n",
    "    \n",
    "    def term_freq(self):\n",
    "        tf = []\n",
    "        for doc in self.data:\n",
    "            doc_count = Counter(doc)\n",
    "            doc_tf = { x: doc_count[x]/len(doc) for x in doc_count}\n",
    "            tf.append(doc_tf)\n",
    "        self.tf  = tf\n",
    "    \n",
    "    def inv_doc_freq(self):\n",
    "        idf = {}\n",
    "        idxs = list(set([j for i in self.data for j in i]))\n",
    "        N = len(self.data)\n",
    "        for idx in idxs:\n",
    "            nd = len([doc for doc in self.data if idx in doc])\n",
    "            idf[idx] = np.log10(1+ (N/nd))\n",
    "        self.idf = idf\n",
    "        \n",
    "    def tfidf_raw(self):\n",
    "        results = []\n",
    "        for doc in self.tf:\n",
    "            result = {}\n",
    "            for idx in doc:\n",
    "                result[idx] = doc[idx] * self.idf[idx]\n",
    "            results.append(result)\n",
    "        self.tfidf_raw_results = results\n",
    "    \n",
    "    def tfidf_id2word(self):\n",
    "        tfidf_results = []\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "        \n",
    "        for doc in self.tfidf_raw_results:\n",
    "            res = {}\n",
    "            for idx in doc:\n",
    "#                 print(idx)\n",
    "#                 print(self.id2word[idx])\n",
    "#                 print(doc[idx])\n",
    "#                 print('---')\n",
    "                \n",
    "                res[self.id2word[idx]] = doc[idx]\n",
    "            tfidf_results.append(res)\n",
    "        return tfidf_results\n",
    "        \n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.tokenizer(X)\n",
    "        self.tfidf_word2id()\n",
    "        self.term_freq()\n",
    "        self.inv_doc_freq()\n",
    "        self.tfidf_raw()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: http://www.home-speech-home.com/speech-therapy-sentences.html\n",
    "# Also made some change to the text for better results\n",
    "data = [\n",
    "    'My mom drove me to school after she talk with me',\n",
    "    'I found a gold coin on the gold school after school today',\n",
    "    'The church was white and brown and look  like a church',\n",
    "    'Your mom is so nice she gave me a ride home today',\n",
    "    'Are you going to have a blue birthday cake for your next birthday',\n",
    "    'My mom made a milkshake with frozen bananas and chocolate sauce',\n",
    "    'I got my haircut today and they did it way too short',\n",
    "    'Your sister is my best friend because she always shares her treats with me',\n",
    "    'The gum was stuck under the desk',\n",
    "    'The flowers smelled beautiful and made the room so happy',\n",
    "    'The dog chased the cat around the block'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords:\n",
    "sw = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDF(stopwords=sw)\n",
    "tfidf.fit(data)\n",
    "res = tfidf.tfidf_id2word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's get the top 3 keyword in each document for validation purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0: \n",
      "\n",
      "[('drove', 0.2697953115119062), ('talk', 0.2697953115119062), ('school', 0.2032283391607139)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 1: \n",
      "\n",
      "[('gold', 0.30833749887074996), ('school', 0.23226095904081587), ('found', 0.15416874943537498)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 2: \n",
      "\n",
      "[('church', 0.35972708201587494), ('white', 0.17986354100793747), ('brown', 0.17986354100793747)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 3: \n",
      "\n",
      "[('nice', 0.17986354100793747), ('gave', 0.17986354100793747), ('ride', 0.17986354100793747)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 4: \n",
      "\n",
      "[('birthday', 0.35972708201587494), ('going', 0.17986354100793747), ('blue', 0.17986354100793747)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 5: \n",
      "\n",
      "[('milkshake', 0.15416874943537498), ('frozen', 0.15416874943537498), ('bananas', 0.15416874943537498)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 6: \n",
      "\n",
      "[('got', 0.215836249209525), ('haircut', 0.215836249209525), ('way', 0.215836249209525)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 7: \n",
      "\n",
      "[('sister', 0.17986354100793747), ('best', 0.17986354100793747), ('friend', 0.17986354100793747)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 8: \n",
      "\n",
      "[('gum', 0.35972708201587494), ('stuck', 0.35972708201587494), ('desk', 0.35972708201587494)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 9: \n",
      "\n",
      "[('flowers', 0.17986354100793747), ('smelled', 0.17986354100793747), ('beautiful', 0.17986354100793747)]\n",
      "\n",
      "======================================================================================================\n",
      "Doc 10: \n",
      "\n",
      "[('dog', 0.215836249209525), ('chased', 0.215836249209525), ('cat', 0.215836249209525)]\n",
      "\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for  i in range(len(res)):\n",
    "    print('Doc {}: \\n'.format(i))\n",
    "    print(\"{}\\n\".format(sorted(res[i].items(),key = lambda x: x[1],reverse=True)[:3]))\n",
    "    print('======================================================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
